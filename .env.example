# Azure OpenAI Configuration for Microsoft Agent Framework
# Copy this file to .env and fill in your values

# Microsoft Agent Framework - Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_OPENAI_API_VERSION=2024-05-01-preview

# Optional: API key (if not using Azure CLI authentication)
# If not provided, the app will use AzureCliCredential (run `az login` first)
# AZURE_OPENAI_API_KEY=your-api-key-here

# ============================================================================
# OBSERVABILITY CONFIGURATION - Microsoft Foundry Tracing & Evaluation
# ============================================================================

# Service identification for OpenTelemetry
OTEL_SERVICE_NAME=writing-agent-editor
OTEL_SERVICE_VERSION=1.0.0

# Enable sensitive data in traces (prompts/responses) - DEV ONLY
# Set to "true" only in development environments
OTEL_ENABLE_SENSITIVE_DATA=false

# Microsoft Foundry integration (recommended for Foundry tracing)
# Get this from Microsoft Foundry portal > Project settings
# Format: https://<resource>.services.ai.azure.com/api/projects/<project-id>
# AZURE_AI_PROJECT_ENDPOINT=https://your-project.services.ai.azure.com/api/projects/your-project

# Application Insights (alternative to Foundry, or for additional monitoring)
# Get this from Azure Portal > Application Insights > Overview > Connection String
# APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=xxx;IngestionEndpoint=https://xxx.applicationinsights.azure.com/

# Enable Azure Monitor live metrics
AZURE_MONITOR_LIVE_METRICS=true

# OTLP endpoint for local development (Aspire Dashboard, Jaeger, etc.)
# Uncomment to send traces to a local OpenTelemetry collector
# Run Aspire Dashboard: docker run -p 18888:18888 -p 4317:4317 -p 4318:4318 mcr.microsoft.com/dotnet/aspire-dashboard:latest
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Environment identifier for deployment tracking
ENVIRONMENT=development
